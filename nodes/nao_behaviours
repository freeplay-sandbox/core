#!/usr/bin/env python
"""
Listens for a trajectory to write and sends it to the nao via naoqi SDK.

Requires a running robot/simulation with ALNetwork proxies.

"""
from copy import deepcopy
from naoqi import ALModule, ALBroker, ALProxy
from geometry_msgs.msg import PoseStamped
from nav_msgs.msg import Path
from std_msgs.msg import String
import rospy
import tf
import motion
import numpy
import math

TO_RAD = math.pi / 180

# masks for which axes naoqi is to control with its planning
axisMask=motion.AXIS_MASK_VEL
#axisMask=motion.AXIS_MASK_ALL

HEAD_FRAME="Head"

NAO_ARM_LENGTH=0.105 #m -> lenght of the link RBicep, from URDF
NAO_FOREARM_LENGTH=0.11 #m -> approx. lenght of forearm + half hand

# See
# http://doc.aldebaran.com/1-14/family/robots/joints_robot.html#robot-joints-v4-left-arm-joints
NAO_RSHOULDER_ANGLE_LIMITS = [-76 * TO_RAD, 18 * TO_RAD]
NAO_RELBOW_ANGLE_LIMITS = [2 * TO_RAD, 88.5 * TO_RAD]

tl = None

def clamp(v, limits):
    vmin, vmax = limits
    return max(min(v, vmax), vmin)


def xyz2pantilt(pose, headframe=HEAD_FRAME):
    """
    Convert a xyz target to pan and tilt angles for the head.

    :param headframe: the frame of the head
    :returns: (pan, tilt) in radians
    """
    #tl.waitForTransform(headframe,pose.header.frame_id, rospy.Time.now(), rospy.Duration(1.0))
    pose.header.stamp = tl.getLatestCommonTime(pose.header.frame_id, headframe)
    transformed_pose = tl.transformPose(headframe, pose)
    pan = numpy.arctan2(transformed_pose.pose.position.y, transformed_pose.pose.position.x)
    tilt = numpy.arctan2(transformed_pose.pose.position.z, transformed_pose.pose.position.x)
    
    return (pan,tilt)

def look_at(pose):
    yaw, pitch = xyz2pantilt(pose)
    yaw = clamp(yaw, (-2.0857, 2.0857))
    pitch = clamp(-pitch, (-0.6720, 0.5149)) #beware the '-pitch'!

    if abs(yaw) < 0.01 and abs(pitch) < 0.01:
       return

    joints = ['HeadYaw','HeadPitch']
    #motionProxy.angleInterpolationWithSpeed(joints, [yaw, pitch], 0.1) # blocking
    speed = 0.1 if abs(yaw) > 0.1 else max(0.005, abs(yaw)) # adapt the speed to the distance to move
    rospy.logdebug("Moving head by: pan: %s, tilt: %s at %s%% of speed" % (yaw, pitch, speed * 100))
    motionProxy.changeAngles(joints, [yaw, pitch], speed) # non-blocking


def arm_ik(targetpose, reference_frame="RShoulder"):
    """
    Returns (shoulder_joint, elbow_joint) such as the arm points towards the
    target (x,y). We make a simple 2D approximation.

              Y
     X target ^
      \  (x,y)|    O
       \      |     \l2
        \     |      \  elbow_joint
         \    |       O
          \   |      /
          `.  |     /l1
           |  |   ,'
            \ |  /
             \| / shoulder_joint
              O:............> X
    """

    targetpose.header.stamp = tl.getLatestCommonTime(targetpose.header.frame_id,reference_frame)
    pose = tl.transformPose(reference_frame, targetpose)

    # rotate the shoulder frame: on the robot, X points forward, on the drawing above, X points right
    x = -pose.pose.position.y
    y = pose.pose.position.x


    l1=NAO_ARM_LENGTH
    l2=NAO_FOREARM_LENGTH

    rospy.logwarn("Target at (%s,%s) from %s" % (x,y,reference_frame))
    if x == 0 and y == 0:
        return None
    if y < 0: # do not allow gestures *behind* the robot
        return None

    if (math.sqrt(x*x + y*y) > l1+l2):
        shoulder_angle = -math.pi/2 + math.atan2(y,x)
        elbow_angle = 0.0
        if shoulder_angle > NAO_RSHOULDER_ANGLE_LIMITS[1]:
            elbow_angle = shoulder_angle

    else:
        # planar solution of the Inverse Kinematic problem
        elbow_angle = math.acos((x*x + y*y - l1*l1 - l2*l2)/(2*l1*l2))
    
        # note: -pi/2 comes from the orientation of Nao's joint (-> angle = 0 <=> arm pointing forward)
        shoulder_angle = -math.pi/2 + math.asin(y/math.sqrt(x*x + y*y)) - math.asin(l2 *
                                                math.sin(elbow_angle)/math.sqrt(x*x + y*y))
    

    return clamp(shoulder_angle, NAO_RSHOULDER_ANGLE_LIMITS),clamp(elbow_angle,NAO_RELBOW_ANGLE_LIMITS)



def point_at(targetpose):
    angles = arm_ik(targetpose)

    if angles is None:
        return

    names  = ["RShoulderRoll",
              "RElbowRoll"]
    rospy.logwarn("Moving shoulder, elbow: %s" % str([angles[0]/TO_RAD, angles[1]/TO_RAD]))
    fractionMaxSpeed  = 0.3
    motionProxy.setAngles(names, angles, fractionMaxSpeed)

def set_pointing_posture():

    names  = ["RShoulderRoll",
              "RShoulderPitch", 
              "RElbowRoll", 
              "RElbowYaw",
              "RWristYaw"]
    angleLists  = [[-10 * TO_RAD, -75 * TO_RAD, -75 * TO_RAD, -35 * TO_RAD],
                   [70 * TO_RAD, 70 * TO_RAD, 10 * TO_RAD],
                   [2 * TO_RAD, 2 * TO_RAD, 60 * TO_RAD],
                   [0 * TO_RAD],
                   [90 * TO_RAD]]
    timeLists   = [[1.0, 3.0,4.0,5.0],
                   [1.0, 3.0, 4.0],
                   [1.0,4.0,5.0],
                   [1.0],
                   [1.0]]
    isAbsolute  = True
    motionProxy.angleInterpolation(names, angleLists, timeLists, isAbsolute)

def arm_to_rest_posture():

    names  = ["RShoulderRoll",
              "RShoulderPitch", 
              "RElbowRoll"]
    angleLists  = [[-75 * TO_RAD, -75 * TO_RAD, -10 * TO_RAD],
                   [10 * TO_RAD, 70 * TO_RAD],
                   [2 * TO_RAD]]
    timeLists   = [[1.0, 3.0, 5.0],
                   [1.0, 3.0],
                   [1.5]]
    isAbsolute  = True
    motionProxy.angleInterpolation(names, angleLists, timeLists, isAbsolute)

def on_traj(traj):
    global tl

    rospy.loginfo("got traj at "+str(rospy.Time.now())) 
    if(hasFallen == False): #no harm in executing trajectory
        #if(effector == "LArm"):
        #    motionProxy.openHand("LHand");
        #    roll = -1.7; #rotate wrist to the left (about the x axis, w.r.t. robot frame)
        #else:
        #    motionProxy.openHand("RHand");
        #    roll = 1.7; #rotate wrist to the right (about the x axis, w.r.t. robot frame)

        target = PoseStamped()

        target_frame = traj.header.frame_id
        target.header.frame_id = target_frame
        
        point_at(traj.poses[0])
        look_at(traj.poses[0])
	rospy.sleep(3)
        point_at(traj.poses[-1])
        look_at(traj.poses[-1])

#        path = []; times = [];
#        for trajp in [traj.poses[0], traj.poses[-1]]:
#
#        
#            trajp.pose.position.z = 0.0
#
#            #print(trajp.pose.position)
#            #print("-")
#
#            target.pose.position = deepcopy(trajp.pose.position)
#            #target.pose.orientation = deepcopy(trajp.pose.orientation)
#            target_robot = tl.transformPose("/base_footprint",target)
#
#            #print(target_robot.pose.position)
#            #print("---")
#
#            point = [target_robot.pose.position.x,target_robot.pose.position.y,target_robot.pose.position.z,roll,0,0]#roll,pitch,yaw];
#            path.append(point);
#            times.append(trajp.header.stamp.to_sec() )#- timeToStartPosition);
#        
#        #wait until time instructed to start executing
#        rospy.sleep(traj.header.stamp-rospy.Time.now())#+rospy.Duration(timeToStartPosition));
#        rospy.loginfo("Executing traj at "+str(rospy.Time.now().to_sec()) + ". Traj: " + str(path) + " (from footprint)") ;
#        rospy.loginfo("Duration requested for this motion: "+str(times));
#        startTime = rospy.Time.now();
#
#        motionProxy.positionInterpolations([effector],[motion.FRAME_ROBOT],[path],[axisMask],[times]);
#        rospy.loginfo("Actual motion duration: "+str((rospy.Time.now()-startTime).to_sec()));

    else:
        rospy.loginfo("Got traj but not allowed to execute it because I've fallen");

class FallResponder(ALModule):
  """ Module to react to robotHasFallen events """
  
  def __init__(self, name, motionProxy, memoryProxy):
      ALModule.__init__(self, name)
      self.motionProxy = motionProxy;
      memoryProxy.subscribeToEvent("robotHasFallen",name,self.has_fallen.__name__);
      rospy.loginfo("Subscribed to robotHasFallen event");
  def has_fallen(self, *_args):
      global hasFallen
      hasFallen = True;
      self.motionProxy.killAll();
      rospy.loginfo("Stopped task");
      
if __name__ == "__main__":

    rospy.init_node("nao_playground_behaviours");
    
    TRAJ_TOPIC = rospy.get_param('~trajectory_input_topic','/playground_manipulation_path')    
    NAO_IP = rospy.get_param('~nao_ip','127.0.0.1'); #default behaviour is 
                                        #to connect to simulator locally
    NAO_HANDEDNESS = rospy.get_param('~nao_handedness','right')
    if(NAO_HANDEDNESS.lower()=='right'):
        effector   = "RArm"
    elif(NAO_HANDEDNESS.lower()=='left'):
        effector = "LArm"
    else: 
        rospy.logerr('error in handedness param')

    pub_speech = rospy.Publisher("/speech", String, queue_size=5)



    # We need this broker to be able to construct
    # NAOqi modules and subscribe to other modules
    # The broker must stay alive until the program exists
    port = 9559;
    myBroker = ALBroker("myBroker", #I'm not sure that pyrobots doesn't already have one of these open called NAOqi?
        "0.0.0.0",   # listen to anyone
        0,           # find a free port and use it
        NAO_IP,      # parent broker IP
        port)        # parent broker port
    hasFallen = False;
    motionProxy = ALProxy("ALMotion", NAO_IP, port);
    memoryProxy = ALProxy("ALMemory", NAO_IP, port);
    postureProxy = ALProxy("ALRobotPosture", NAO_IP, port)
    #fallResponder = FallResponder("fallResponder",motionProxy,memoryProxy);
    
    motionProxy.wbEnableEffectorControl(effector,False); #if robot has fallen it will have a hard time getting up if the effector is still trying to be kept in a particular position
    motionProxy.wakeUp()
    postureProxy.goToPosture("StandInit", 0.5)

    set_pointing_posture()

    motionProxy.wbEnableEffectorControl(effector,True);
    rospy.sleep(2)

    tl = tf.TransformListener()

    ### Check the robot is launched and properly localised wrt the sandtray
    while not rospy.is_shutdown():
        if not tl.frameExists("/odom"):
            rospy.logwarn("Waiting for frame /odom to be published...")
        else:
            try:
                t = tl.getLatestCommonTime("odom", "sandtray")
      	        if tl.canTransform("odom", "sandtray",t):
                    rospy.loginfo("Ok! Starting robot behaviours.")
                    pub_speech.publish(String("Ready to go!"))
                    break
                else:
                    rospy.logwarn("No transform robot->sandtray. Robot not yet localised!")
            except:
                rospy.logwarn("No transform robot->sandtray. Robot not yet localised!")

        rospy.sleep(0.5)


    #sub_traj = rospy.Subscriber(TRAJ_TOPIC, Path, on_traj)

    r = rospy.Rate(2)

    while not rospy.is_shutdown():
        try:
            t = tl.getLatestCommonTime(HEAD_FRAME, "robot_focus")
            if tl.canTransform(HEAD_FRAME, "robot_focus",t):
                robot_focus = PoseStamped()
                robot_focus.header.stamp = rospy.Time.now()
                robot_focus.header.frame_id = "robot_focus"
                look_at(robot_focus)
                point_at(robot_focus)
        except: # most likely, robot_focus is not published. That's ok, don't track it then
            pass

        r.sleep()


    arm_to_rest_posture()
    motionProxy.rest()

    myBroker.shutdown()
